# A unique identifier for the head node and workers of this cluster.
cluster_name: dev

max_workers: 5

available_node_types:
    ray_head_default:
        min_workers: 0
        max_workers: 0
        resources: {"CPU": 1}
        # Provider-specific config for this node type, e.g. instance type. By default
        # Ray will auto-configure unspecified fields such as subnets and ssh-keys.
        # For more documentation on available fields, see:
        # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert
        node_config:
            machineType: n1-standard-4
            disks:
              - boot: true
                autoDelete: true
                type: PERSISTENT
                initializeParams:
                  diskSizeGb: 50
                  # See https://cloud.google.com/compute/docs/images for more images
                  sourceImage: projects/ubuntu-os-cloud/global/images/family/ubuntu-2004-lts
    ray_tpu:
        min_workers: 1
        max_workers: 2
        resources: {"TPU": 1}  # use TPU custom resource in your code
        node_config:
            acceleratorType: v4-8
            runtimeVersion: tpu-vm-v4-base
        worker_setup_commands:
            - pip install 'jax[tpu]==0.4.11' -f https://storage.googleapis.com/jax-releases/libtpu_releases.html
    ray_worker_gpu:
        min_workers: 0
        max_workers: 2
        resources: {"CPU": 2, "GPU": 1}
        # Provider-specific config for the head node, e.g. instance type. By default
        # Ray will auto-configure unspecified fields such as subnets and ssh-keys.
        # For more documentation on available fields, see:
        # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert
        node_config:
            machineType: a2-highgpu-1g
            disks:
              - boot: true
                autoDelete: true
                type: PERSISTENT
                initializeParams:
                  diskSizeGb: 50
                  # See https://cloud.google.com/compute/docs/images for more images
                  sourceImage: projects/deeplearning-platform-release/global/images/family/pytorch-latest-gpu
            # Make sure to set scheduling->onHostMaintenance to TERMINATE when GPUs are present
            guestAccelerators:
              - acceleratorType: nvidia-tesla-a100
                acceleratorCount: 1
            metadata:
              items:
                - key: install-nvidia-driver
                  value: "True"
            # Run workers on preemtible instance by default.
            # Comment this out to use on-demand.
            scheduling:
              - preemptible: true
              - onHostMaintenance: TERMINATE


provider:
    type: gcp
    region: us-central1
    availability_zone: us-central1-a
    tpu_zone: us-central2-b
    project_id: mlperf-high-priority-project

initialization_commands:
  - sudo apt-get update
  - sudo apt-get install -y python3-pip python-is-python3
  - pip install "pydantic<2"
  - pip install --upgrade urllib3
  - pip install "ray[default]"
  - pip install /home/ubuntu/ray-3.0.0.dev0-cp38-cp38-manylinux2014_x86_64.whl

head_setup_commands:
  - pip install google-api-python-client
  - rm -rf ~/.local/lib/python3.8/site-packages/ray/autoscaler
  - cp -R ~/autoscaler ~/.local/lib/python3.8/site-packages/ray/

file_mounts: {
    "/home/ubuntu/autoscaler": "/home/allencwang/ray/python/ray/autoscaler",
    "/home/ubuntu/ray-3.0.0.dev0-cp38-cp38-manylinux2014_x86_64.whl": "/home/allencwang/ray-3.0.0.dev0-cp38-cp38-manylinux2014_x86_64.whl",
    "/home/ubuntu/apps": "/home/allencwang/ray/apps-dev",
}

# Specify the node type of the head node (as configured above).
head_node_type: ray_head_default

worker_start_ray_commands:
  - ray stop
  - "export HOSTNAME_VAL=\"$(hostnamectl | grep 'Static hostname' | awk '{print $3}' | sed 's/-w-.*//')\"; ulimit -n 65536; ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076 --resources=\"{\\\"$HOSTNAME_VAL-tpu\\\": 1}\""

